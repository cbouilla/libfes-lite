import sys

L = 8

def ffs(i):
    if i == 0:
        return -1
    k = 0
    while i & 0x0001 == 0:
        k += 1
        i >>= 1
    return k

def idxq(i, j):
    assert i < j
    return i + j * (j - 1) // 2


print("""
################################################################################
# This file was auto-generated by {script}
# The loop is unrolled {unroll} times
################################################################################
""".format(script=sys.argv[0], unroll=2**L))

print("""
# the System V AMD64 ABI says that :
#Â A) The first six integer or pointer arguments are passed in registers RDI, RSI, RDX, RCX, R8, R9
# B) we should preserve the values of %rbx, %rbp, %r12...%r15 [callee-save registers]
# C) We will receive the arguments of the function in registers :
#       Fq           in %rdi
#       Fl           in %rsi
#       alpha        in %rdx
#       beta         in %rcx
#       gamma        in %r8
# D) we return the mask in %rax

# no need to save the callee-save registers (we do not touch them)
# Load the 13 most used values into %ymm0-%ymm12
# %ymm15 is pinned to zero
# %ymm14 is used for temporary storage (could be dispensed with)
# %ymm13 contains the mask

# we may still use %9, %r10 and %r11
# %r11 contains the comparison output mask 
# %r9 and %r10 are available

# This uses only "light" AVX2 instructions (no FP, no MUL). But cores runs at "AVX2" speed.
# Scheduling on Haswell : each step is 4 instructions ;
#   three steps send 4 uops to ports 0,1,5  (in the best case)
#   three steps thus take at least 4 cycles
#   peak performance is then 16x3 candidates in 4 cycles --> 12 candidates/cycle
# 
# Measured : 5.75 cycles for three steps without hyperthreading
# Measured : 4.45 cycles for three steps with hyperthreading
#
# This is a 35% speedup wrt the non-batch version. Even with 10% additionnal work afterwards, there is a clear gain.

### extern u32 feslite_avx2_asm_enum_batch(const __m256i * Fq, __m256i * Fl, u64 alpha, u64 beta, u64 gamma)

.text
.p2align 5

.globl feslite_avx2_asm_enum_batch
feslite_avx2_asm_enum_batch:

# multiply alpha, beta, gamma by 32
shlq $5, %rdx
shlq $5, %rcx
shlq $5, %r8

vpxor %ymm15, %ymm15, %ymm15         # set %ymm15 to always-zero
vpxor %ymm13, %ymm13, %ymm13         # initialize acc (%ymm13) to zero

movq %r9, %rax                       # prepare the return value
""")

Fl = {}
Fl[0] = "%ymm0"   # 1
Fl[1] = "%ymm1"   # 1/2
Fl[2] = "%ymm2"   # 1/4
Fl[3] = "%ymm3"   # 1/8
Fl[4] = "%ymm4"   # 1/16
Fl[5] = "%ymm5"   # 1/32
Fl[6] = "%ymm6"   # 1/64

Fq = {}
Fq[idxq(0, 1)] = "%ymm7"  # 1/4
Fq[idxq(0, 2)] = "%ymm8"  # 1/8
Fq[idxq(1, 2)] = "%ymm9"  # 1/8
Fq[idxq(0, 3)] = "%ymm10"  # 1/16
Fq[idxq(1, 3)] = "%ymm11" # 1/16
Fq[idxq(2, 3)] = "%ymm12" # 1/16

assert Fl[0] == "%ymm0"

def output_comparison(i, between_cmp_or=None):
    # before the XORs, the comparison
    print('vpcmpeqd %ymm0, %ymm15, %ymm15'.format())
    if between_cmp_or:
        print(between_cmp_or)
    print('vpor %ymm15, %ymm13, %ymm13')

stats = {'reg/reg': 0, 'mem/reg': 0, 'mem/mem': 0}

def compute_update(i, a, b):
    # There are 3 possible cases :
    # 1a. Fq in register, Fl in register
    # 1b. Fq in memory,   Fl in register
    #  2. Fq in memory,   Fl in memory
    if a in Fl:
        if b in Fq: # reg / reg
            stats['reg/reg'] += 1
            xor1 = "vpxor {src}, {dst}, {dst}".format(src=Fq[b], dst=Fl[a])
        elif Fq_memref is None: # mem / reg
            stats['mem/reg'] += 1
            xor1 = "vpxor {offset}(%rdi), {dst}, {dst}".format(offset=32*b, dst=Fl[a])
        else: # mem(alpha) / reg
            stats['mem/reg'] += 1
            xor1 = "vpxor {src}, {dst}, {dst}".format(src=Fq_memref, dst=Fl[a])
        xor2 = "vpxor {src}, %ymm0, %ymm0".format(src=Fl[a])
        return (xor1, xor2)

    else:             # (a not in Fl)
        stats['mem/mem'] += 1
        assert b not in Fq
        xor1a = "vmovdqa {offset}(%rsi), %ymm14".format(offset=32*a) # load Fl[a]
        if Fq_memref is None: 
            xor1b = "vpxor {offset}(%rdi), %ymm14, %ymm14".format(offset=32*b)
        else:
            xor1b = "vpxor {src}, %ymm14, %ymm14".format(src=Fq_memref)
        xor1c = "vmovdqa %ymm14, {offset}(%rsi)".format(offset=32*a) # store Fl[a]
        xor2 = "vpxor %ymm14, %ymm0, %ymm0"
        return ("\n".join([xor1a, xor1b, xor1c]), xor2)

###################""

print( "# load the most-frequently used values into vector registers" )
for i, reg in Fl.items():
    print("vmovdqa {offset}(%rsi), {reg}   ## {reg} = Fl[{i}]".format(offset=i*32, reg=reg, i=i))
print()
for x, reg in Fq.items():
    print("vmovdqa {offset}(%rdi), {reg}   ## {reg} = Fq[{idx}]".format(offset=x*32, reg=reg, idx=x))
print()

alpha = 0
for i in range((1 << L) - 1):
    ########################## UNROLLED LOOP #######################################
    idx1 = ffs(i + 1)                       
    idx2 = ffs((i + 1) ^ (1 << idx1))
    a = idx1 + 1                              # offset dans Fl
    Fq_memref = None
    if idx2 == -1:
        Fq_memref = "{offset}(%rdi, %rdx)".format(offset=32*alpha)
        b = "alpha + {}".format(alpha)
        alpha += 1
    else:
        assert idx1 < idx2
        b = idxq(idx1, idx2)                  # offset dans Fq

    print()
    print('##### step {:3d} : Fl[0] ^= (Fl[{}] ^= Fq[{}])'.format(i, a, b))
    print()
    xor1, xor2 = compute_update(i, a, b)
    output_comparison(i)
    print(xor1)
    print(xor2)
    print()

####### ne pas oublier le dernier tour special
print('#############################')
print('# end of the unrolled chunk #')
print('#############################')
print()
print("# Save the Fl[1:] back to memory")
for i, reg in Fl.items():
    if i == 0:
        continue
    print("vmovdqa {reg}, {offset:2d}(%rsi)     #Fl[{i}] <-- {reg}".format(offset=i*32, reg=reg, i=i))
print()
print('##### special last step {:3d} : Fl[0] ^= (Fl[beta] ^= Fq[gamma])'.format((1 << L) - 1))
print()
output_comparison((1 << L) - 1)
print("vmovdqa (%rsi, %rcx), %ymm14")     # load Fl[beta]
print("vpxor (%rdi, %r8), %ymm14, %ymm14")        # xor Fq[gamma]
print("vmovdqa %ymm14, (%rsi, %rcx)")     # store Fl[beta]
print("vpxor %ymm14, %ymm0, %ymm0")
print()
print("# Save Fl[0] back to memory")
print("vmovdqa %ymm0, (%rsi)     #Fl[0] <-- %ymm0")
print()
print("# Save acc back to memory")
print("vpmovmskb %ymm13, %eax     #return value <-- %ymm13")

print('ret')
print()
print("####################################################")
print("# Stats")
print("# reg / reg : {}".format(stats['reg/reg']))
print("# mem / reg : {}".format(stats['mem/reg']))
print("# mem / mem : {}".format(stats['mem/mem']))
